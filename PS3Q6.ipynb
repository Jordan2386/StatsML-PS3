{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainx = pd.read_csv(\"usps_trainx.data\", header=None, delimiter=r\"\\s+\")\n",
    "trainy = pd.read_csv(\"usps_trainy.data\", header=None, delimiter=r\"\\s+\")\n",
    "testx = pd.read_csv(\"usps_testx.data\", header=None, delimiter=r\"\\s+\")\n",
    "testy = pd.read_csv(\"usps_testy.data\", header=None, delimiter=r\"\\s+\")\n",
    "\n",
    "im_height = 16 #image height\n",
    "im_width = 16 #image width\n",
    "num_classes = 10 #number of classes for classificaiton\n",
    "\n",
    "#normalise the images\n",
    "trainx = trainx / 256\n",
    "testx  = testx  / 256\n",
    "\n",
    "#transform pandas to numpy arrays\n",
    "trainx = trainx.as_matrix()\n",
    "trainy = trainy.as_matrix()\n",
    "testx = testx.as_matrix()\n",
    "testy = testy.as_matrix()\n",
    "\n",
    "#remove the second dimensions:\n",
    "trainy = trainy[:,0]\n",
    "testy = testy[:,0]\n",
    "\n",
    "#randomly shuffle the train data\n",
    "import random\n",
    "random_idx = random.sample([x for x in range(len(trainx))],len(trainx))\n",
    "trainx = trainx[random_idx,]\n",
    "trainy = trainy[random_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform the images in a 16x16 form; the resulting tensor would be 2000x16x16 both for training and for test data.\n",
    "# Simplified by Dr Seth Flaxman\n",
    "trainx = trainx.reshape(len(trainx),16,16)\n",
    "testx = testx.reshape(len(trainx),16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1-hot encode the labels trainy and testy\n",
    "# Simplified by Dr Seth Flaxman\n",
    "trainy = pd.get_dummies(trainy).as_matrix()\n",
    "testy = pd.get_dummies(testy).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some notation for convenience\n",
    "train_size = len(trainx)\n",
    "test_size = len(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract batches funciton that returns a dictionary ready to be fed to the model\n",
    "\n",
    "def next_batch(data_x,data_y,indices):\n",
    "    return data_x[indices,:,:] , data_y[indices,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the convolution operation (with relu activation), and the maxpool operation\n",
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/convolutional_network.ipynb\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"   \\n    # Feed Dict and RUN SESSION\\n    num_batches = int(len(trainx)/batch_size)\\n\\n    sess = tf.Session()\\n    tf.global_variables_initializer().run(session=sess)\\n    # Feed the batches one by one\\n    for t in range(num_epochs):\\n        for i in range(num_batches):\\n            batch_X, batch_y = next_batch(trainx,trainy,[x for x in range(len(trainx))][i*batch_size:(i+1)*batch_size])\\n            sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONSTRUCT THE COMPUTATIONAL GRAPH\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "# an epoch is one run over all the training data\n",
    "num_epochs = 60  #optimal: 400\n",
    "learning_rate = 0.001\n",
    "\n",
    "c = 5 #convolution window size\n",
    "stride = 2 #stride of the convolution\n",
    "conv1_size = 64 #number of outputs from the conv layer\n",
    "\n",
    "c2 = 5 #2nd convolution window size\n",
    "stride_2 = 2 #stride of the 2nd convolution\n",
    "conv2_size = 32 #number of outputs from the 2nd conv layer\n",
    "\n",
    "full_conn_size = 1024 #number of nodes in the fully connected layer\n",
    "\n",
    "compute_graph = tf.Graph()\n",
    "# CONSTRUCT THE GRAPH\n",
    "with compute_graph.as_default():\n",
    "    \n",
    "    #introduce placeholders for the data(images and labels) to later feed batches into\n",
    "    X = tf.placeholder(tf.float32, shape=(batch_size,im_height,im_width)) #images\n",
    "    y = tf.placeholder(tf.int32, shape=(batch_size,num_classes)) #labels\n",
    "    \n",
    "    #transform input into a 4d tensor to include the colour channels\n",
    "    X_prime = tf.reshape(X, shape=[-1, im_height, im_width, 1])\n",
    "    \n",
    "    #define the parameters(variables) of the model\n",
    "    #for the convolution layer:\n",
    "    W1 = tf.Variable(tf.random_normal([c, c, 1, conv1_size]))\n",
    "    b1 = tf.Variable(tf.random_normal([conv1_size]))\n",
    "    #for the second convolution layer:\n",
    "    W2 = tf.Variable(tf.random_normal([c2, c2, conv1_size, conv2_size]))\n",
    "    b2 = tf.Variable(tf.random_normal([conv2_size]))\n",
    "    #for the fully connected layer:\n",
    "    W3 = tf.Variable(tf.random_normal([1*1*conv2_size, full_conn_size]))\n",
    "    b3 = tf.Variable(tf.random_normal([full_conn_size]))\n",
    "    #for the output:\n",
    "    WO = tf.Variable(tf.random_normal([full_conn_size, num_classes]))\n",
    "    bO = tf.Variable(tf.random_normal([num_classes]))\n",
    "    \n",
    "    \n",
    "    #define the model structure\n",
    "    # c x c convolution, 1 input, conv1_size outputs\n",
    "    convolution = conv2d(X_prime, W1, b1, stride)\n",
    "    # then apply pooling\n",
    "    pool = maxpool2d(convolution)\n",
    "    \n",
    "    #one more convolution+pooling layer:\n",
    "    convolution2 = conv2d(pool, W2, b2, stride_2)\n",
    "    # then apply pooling\n",
    "    pool2 = maxpool2d(convolution2)\n",
    "    \n",
    "    \n",
    "    #add a fully connected layer\n",
    "    # Reshape convolution output to fit the fully connected layer input\n",
    "    full_conn = tf.reshape(pool2, [-1, 1*1*conv2_size])\n",
    "    full_conn = tf.add(tf.matmul(full_conn, W3), b3)\n",
    "    full_conn = tf.nn.relu(full_conn)\n",
    "    \n",
    "\n",
    "    # Output, class prediction\n",
    "    predictions = tf.add(tf.matmul(full_conn, WO), bO)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "    # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/convolutional_network.ipynb\n",
    "    correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "\"\"\"\"   \n",
    "    # Feed Dict and RUN SESSION\n",
    "    num_batches = int(len(trainx)/batch_size)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    tf.global_variables_initializer().run(session=sess)\n",
    "    # Feed the batches one by one\n",
    "    for t in range(num_epochs):\n",
    "        for i in range(num_batches):\n",
    "            batch_X, batch_y = next_batch(trainx,trainy,[x for x in range(len(trainx))][i*batch_size:(i+1)*batch_size])\n",
    "            sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\n",
    "\"\"\"\n",
    "\n",
    "#    for _ in range(1000):\n",
    "#        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-60-35aac324d7af>:21 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Train accuracy at epoch 1 is: 0.340555562948\n",
      "Valid accuracy at epoch 1 is: 0.560000011325\n",
      "Train accuracy at epoch 2 is: 0.656111123164\n",
      "Valid accuracy at epoch 2 is: 0.715000014007\n",
      "Train accuracy at epoch 3 is: 0.776666676584\n",
      "Valid accuracy at epoch 3 is: 0.755000011995\n",
      "Train accuracy at epoch 4 is: 0.834444452822\n",
      "Valid accuracy at epoch 4 is: 0.805000010878\n",
      "Train accuracy at epoch 5 is: 0.880555562013\n",
      "Valid accuracy at epoch 5 is: 0.830000008643\n",
      "Train accuracy at epoch 6 is: 0.908888893988\n",
      "Valid accuracy at epoch 6 is: 0.8600000076\n",
      "Train accuracy at epoch 7 is: 0.932222226097\n",
      "Valid accuracy at epoch 7 is: 0.800000010431\n",
      "Train accuracy at epoch 8 is: 0.935000003874\n",
      "Valid accuracy at epoch 8 is: 0.880000006407\n",
      "Train accuracy at epoch 9 is: 0.955000002682\n",
      "Valid accuracy at epoch 9 is: 0.850000008196\n",
      "Train accuracy at epoch 10 is: 0.958888891132\n",
      "Valid accuracy at epoch 10 is: 0.840000008792\n",
      "Train accuracy at epoch 15 is: 0.983333334327\n",
      "Valid accuracy at epoch 15 is: 0.885000006109\n",
      "Train accuracy at epoch 20 is: 0.985555556417\n",
      "Valid accuracy at epoch 20 is: 0.890000005811\n",
      "Train accuracy at epoch 25 is: 0.991111111641\n",
      "Valid accuracy at epoch 25 is: 0.905000004917\n",
      "Train accuracy at epoch 30 is: 0.991666667163\n",
      "Valid accuracy at epoch 30 is: 0.910000004619\n",
      "Train accuracy at epoch 35 is: 0.99777777791\n",
      "Valid accuracy at epoch 35 is: 0.925000003725\n",
      "Train accuracy at epoch 40 is: 0.995000000298\n",
      "Valid accuracy at epoch 40 is: 0.940000003576\n",
      "Train accuracy at epoch 45 is: 0.993888889253\n",
      "Valid accuracy at epoch 45 is: 0.930000003427\n",
      "Train accuracy at epoch 50 is: 0.99777777791\n",
      "Valid accuracy at epoch 50 is: 0.940000003576\n",
      "Train accuracy at epoch 55 is: 0.996666666865\n",
      "Valid accuracy at epoch 55 is: 0.925000003725\n",
      "Train accuracy at epoch 60 is: 0.998333333433\n",
      "Valid accuracy at epoch 60 is: 0.92500000298\n"
     ]
    }
   ],
   "source": [
    "# TUNE HYPERPARAMETERS\n",
    "# Note: this can take a while to run\n",
    "# Extract (from the test set) a small validation set to test the model accuracy while tuning the hyperparameters\n",
    "\n",
    "valid_size = 200\n",
    "\n",
    "trainx_ = trainx[0:train_size-valid_size]\n",
    "trainy_ = trainy[0:train_size-valid_size]\n",
    "validx = trainx[train_size-valid_size:]\n",
    "validy = trainy[train_size-valid_size:]\n",
    "\n",
    "num_train_batches = int(len(trainx_)/batch_size)\n",
    "train_accuracy = np.zeros(num_train_batches)\n",
    "\n",
    "num_valid_batches = int(len(validx)/batch_size)\n",
    "valid_accuracy = np.zeros(num_valid_batches)\n",
    "\n",
    "\n",
    "# Initialise all variables and run the session:\n",
    "with tf.Session(graph=compute_graph) as sess:\n",
    "    tf.initialize_all_variables().run(session=sess)\n",
    "    \n",
    "    # Feed the batches one by one\n",
    "    for t in range(num_epochs):\n",
    "        for i in range(num_train_batches):\n",
    "            batch_X, batch_y = next_batch(trainx_,trainy_,[x for x in range(train_size-valid_size)][i*batch_size:(i+1)*batch_size])\n",
    "            sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\n",
    "            train_accuracy[i] = sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})\n",
    "        \n",
    "        # report train/valid accuracy regularly in order to perform early stoping\n",
    "        if((t+1) % 100 == 0 or ((t+1) % 5 == 0 and (t+1) <= 100) or (t+1) <= 10):\n",
    "            print(\"Train accuracy at epoch\", t+1, \"is:\", sum(train_accuracy)/num_train_batches)\n",
    "            # validation accuracy\n",
    "            for i in range(num_valid_batches):\n",
    "                batch_X, batch_y = next_batch(validx,validy,[x for x in range(valid_size)][i*batch_size:(i+1)*batch_size])\n",
    "                sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})\n",
    "                valid_accuracy[i] = sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})\n",
    "            print(\"Valid accuracy at epoch\", t+1, \"is:\", sum(valid_accuracy)/num_valid_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TUNE HYPERPARAMETERS\n",
    "# Do cross-validation to check the model performance and tune the parameters (num layers, layer types, batch size, etc.)\n",
    "# Note: it's not wise to use the test set in hyperparameter tuning\n",
    "\n",
    "#num_cross_valid = 10 #number of cross-validation sectors\n",
    "#train_accuracy = np.zeros(num_cross_valid)\n",
    "\n",
    "# Train the model on each 9 of the 10 train data sectors, while recording the test accuracy on the remaining segment\n",
    "#for i in range(num_cross_valid):\n",
    "#    train_batch_X, train_batch_y = next_batch(trainx,trainy,[x for x in range(len(trainx))][i*batch_size:(i+1)*batch_size])\n",
    "#    sess.run(optimizer, feed_dict={X: train_batch_X, y: train_batch_y})\n",
    "#    test_batch_X, test_batch_y = next_batch(trainx,trainy,[x for x in range(len(trainx))][i*batch_size:(i+1)*batch_size])\n",
    "#    train_accuracy[i] = sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-61-3983e57cbf6f>:11 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "The train accuracy at epoch 1 is: 0.427500009723\n",
      "The train accuracy at epoch 2 is: 0.690500013158\n",
      "The train accuracy at epoch 3 is: 0.798500010185\n",
      "The train accuracy at epoch 4 is: 0.853500008211\n",
      "The train accuracy at epoch 5 is: 0.889000006318\n",
      "The train accuracy at epoch 6 is: 0.919000004753\n",
      "The train accuracy at epoch 7 is: 0.931500004008\n",
      "The train accuracy at epoch 8 is: 0.94950000301\n",
      "The train accuracy at epoch 9 is: 0.957500002533\n",
      "The train accuracy at epoch 10 is: 0.967500001937\n",
      "The train accuracy at epoch 20 is: 0.992000000477\n",
      "The train accuracy at epoch 30 is: 0.993500000387\n",
      "The train accuracy at epoch 40 is: 1.0\n",
      "The train accuracy at epoch 50 is: 1.0\n",
      "The train accuracy at epoch 60 is: 1.0\n",
      "The test accuracy is  0.935500003472\n"
     ]
    }
   ],
   "source": [
    "# NOW TRAIN THE MODEL OVER THE WHOLE DATASET AND REPORT TEST ACCURACY\n",
    "\n",
    "num_batches = int(train_size/batch_size)\n",
    "train_accuracy = np.zeros(num_batches)\n",
    "\n",
    "num_test_batches = int(test_size/batch_size)\n",
    "accuracy_ = np.zeros(num_test_batches)\n",
    "\n",
    "# Initialise all variables and run the session\n",
    "with tf.Session(graph=compute_graph) as sess:\n",
    "    tf.initialize_all_variables().run(session=sess)\n",
    "\n",
    "    # Feed the batches one by one\n",
    "    for t in range(num_epochs):\n",
    "        for i in range(num_batches):\n",
    "            batch_X, batch_y = next_batch(trainx,trainy,[x for x in range(train_size)][i*batch_size:(i+1)*batch_size])\n",
    "            sess.run(optimizer, feed_dict={X: batch_X, y: batch_y})\n",
    "            train_accuracy[i] = sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})\n",
    "        if((t+1) % 100 == 0 or ((t+1) % 10 == 0 and (t+1) <= 100) or (t+1) <= 10):\n",
    "            print(\"The train accuracy at epoch\", t+1, \"is:\", sum(train_accuracy)/num_batches)\n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    for i in range(num_test_batches):\n",
    "        batch_X, batch_y = next_batch(testx,testy,[x for x in range(len(testx))][i*batch_size:(i+1)*batch_size])\n",
    "        accuracy_[i] = sess.run(accuracy, feed_dict={X: batch_X, y: batch_y})\n",
    "        \n",
    "    print(\"The test accuracy is \",sum(accuracy_)/num_test_batches)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
